{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1qUujIuJBXRw1PKuRwqJjSRGAHcaWnB9c","authorship_tag":"ABX9TyMTP70YjsCntuH6+Sm21JyI"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HwwUEcRNzRMv","executionInfo":{"status":"ok","timestamp":1612468035947,"user_tz":-60,"elapsed":2610984,"user":{"displayName":"Bianca Barattolo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZTf-PEXZ3X6d660r5W6EvdxzK1lhMipTiEg0=s64","userId":"02300857865683458065"}},"outputId":"d21c5967-afe6-4d2e-fbb3-70caa078822d"},"source":["import pandas as pd\r\n","import numpy as np\r\n","from numpy import mean\r\n","from numpy import std\r\n","from numpy import dstack\r\n","from pandas import read_csv\r\n","import pickle\r\n","from scipy import stats\r\n","import keras\r\n","from keras.models import Sequential\r\n","from keras.layers import Dense\r\n","from keras.layers import Flatten\r\n","from keras.layers import Dropout\r\n","from keras.layers import LSTM\r\n","from keras.layers import TimeDistributed\r\n","from keras.layers import Conv1D\r\n","from keras.layers import MaxPooling1D\r\n","from keras.utils import to_categorical\r\n","from matplotlib import pyplot\r\n","import tensorflow as tf\r\n","from sklearn import metrics\r\n","from sklearn.model_selection import train_test_split\r\n","\r\n","fileweights = 'drive/MyDrive/Colab Notebooks/weights/w.hdf5'\r\n","RANDOM_SEED = 42\r\n","\r\n","# load the dataset, returns train and test X and y elements\r\n","def load_WISDM_dataset(prefix=''):\r\n","  columns = ['user','activity','timestamp', 'x-axis', 'y-axis', 'z-axis']\r\n","  df = pd.read_csv(prefix + 'WISDM/WISDM_ar_v1.1_raw.txt', header = None, names = columns)\r\n","  df = df.dropna()\r\n","\r\n","  N_TIME_STEPS = 200\r\n","  N_FEATURES = 3\r\n","  step = 20\r\n","  segments = []\r\n","  labels = []\r\n","  \r\n","  for i in range(0, len(df) - N_TIME_STEPS, step):\r\n","    xs = df['x-axis'].values[i: i + N_TIME_STEPS]\r\n","    ys = df['y-axis'].values[i: i + N_TIME_STEPS]\r\n","    zs = df['z-axis'].values[i: i + N_TIME_STEPS]\r\n","    label = stats.mode(df['activity'][i: i + N_TIME_STEPS])[0][0]\r\n","    segments.append([xs, ys, zs])\r\n","    labels.append(label)\r\n","  \r\n","  print(np.array(segments).shape)\r\n","\r\n","  reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, N_TIME_STEPS, N_FEATURES)\r\n","  labels = np.asarray(pd.get_dummies(labels), dtype = np.float32)\r\n","\r\n","  X_train, X_test, y_train, y_test = train_test_split(reshaped_segments, labels, test_size=0.2, random_state=RANDOM_SEED)\r\n","  return X_train, y_train, X_test, y_test\r\n","\r\n","def method_to_create_the_model(n_length, n_features, n_outputs):\r\n","\t# define model\r\n","  model = Sequential()\r\n","  model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'), input_shape=(None,n_length,n_features)))\r\n","  model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\r\n","  model.add(TimeDistributed(Dropout(0.5)))\r\n","  model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\r\n","  model.add(TimeDistributed(Flatten()))\r\n","  model.add(LSTM(100))\r\n","  model.add(Dropout(0.5))\r\n","  model.add(Dense(100, activation='relu'))\r\n","  model.add(Dense(n_outputs, activation='softmax'))\r\n","  return model\r\n","\r\n","# fit and evaluate a model\r\n","def evaluate_model(trainX, trainy, testX, testy):\r\n","  # define model\r\n","  verbose, epochs, batch_size = 0, 50, 64\r\n","  n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\r\n","  # reshape into subsequences (samples, time steps, rows, cols, channels)\r\n","  n_steps, n_length = 20, 200\r\n","\r\n","  print(trainX.shape)\r\n","  #questo 1 da dove viene?\r\n","  trainX = trainX.reshape(trainX.shape[0], 1, n_length, n_features)\r\n","  testX = testX.reshape(testX.shape[0], 1, n_length, n_features)\r\n","\r\n","  model = method_to_create_the_model(n_length, n_features, n_outputs)\r\n","    \r\n","  save_weights = keras.callbacks.ModelCheckpoint(fileweights, save_weights_only=True) #, period=5)\r\n","  \r\n","  earlyStopping = keras.callbacks.EarlyStopping(monitor='loss', patience=10, verbose=0, mode='min')\r\n","\r\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n","  # fit network\r\n","  model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose, callbacks=[save_weights, earlyStopping])\r\n","  # evaluate model\r\n","  _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\r\n","  return accuracy\r\n","\t\r\n","def evaluate_network(testX):\r\n","  n_steps, n_length = 20, 200\r\n","  n_features = 3\r\n","  n_outputs = 6\r\n","\r\n","  print(testX.shape[0])\r\n","  testX = testX.reshape((testX.shape[0], 1, n_length, n_features))\r\n","  model = method_to_create_the_model(n_length, n_features, n_outputs)\r\n","  model.load_weights(fileweights)\r\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n","  predictions = model.predict(testX)\r\n","  for pred in predictions:\r\n","    print(pred)\r\n","\t\t\r\n","\r\n","def compare_features(feature1, feature2):\r\n","\tsimilarity = DWT(feature1, feature2)\r\n","\treturn similarity\r\n","\t\t\r\n","def extract_features(testX):\r\n","\tmodel = method_to_create_the_model(n_length, n_features)\r\n","\tmodel.load_weights(fileweights)\r\n","  #controllare se -4 va bene\r\n","\textract = Model(model.inputs, model.layers[-4].output) \r\n","\tfeatures_list = []\r\n","\tfor test in testX:\r\n","\t\tfeatures = extract.predict(test)\r\n","\t\tsave_features(features)\r\n","\t\tfeatures_list.append(features)\r\n","\treturn features_list\r\n","\r\n","# summarize scores\r\n","def summarize_results(scores):\r\n","\tprint(scores)\r\n","\tm, s = mean(scores), std(scores)\r\n","\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\r\n"," \r\n","# run an experiment\r\n","def run_experiment(repeats=1):\r\n","\t# load data\r\n","\ttrainX, trainy, testX, testy = load_WISDM_dataset('drive/MyDrive/Colab Notebooks/')\r\n","\t# repeat experiment\r\n","\tscores = list()\r\n","\tfor r in range(repeats):\r\n","\t\tscore = evaluate_model(trainX, trainy, testX, testy)\r\n","\t\tscore = score * 100.0\r\n","\t\tprint('>#%d: %.3f' % (r+1, score))\r\n","\t\tscores.append(score)\r\n","\t# summarize results\r\n","\tsummarize_results(scores)\r\n","\r\n","# run the experiment\r\n","run_experiment()\r\n","\r\n","#trainX, trainy, testX, testy = load_WISDM_dataset('drive/MyDrive/Colab Notebooks/')\r\n","#evaluate_network(testX)\r\n"],"execution_count":22,"outputs":[{"output_type":"stream","text":["(54901, 3, 200)\n","(43920, 200, 3)\n",">#1: 98.525\n","[98.5247254371643]\n","Accuracy: 98.525% (+/-0.000)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gJ1HVngJYrrL"},"source":["# Dati estratti con Early Stopping = loss"]},{"cell_type":"markdown","metadata":{"id":"JzvErlohS9Il"},"source":["run_experiment() del 04/02\r\n","\r\n","(54901, 3, 200)\r\n","(43920, 200, 3)\r\n",">#1: 98.525\r\n","[98.5247254371643]\r\n","\r\n","Accuracy: 98.525% (+/-0.000)"]},{"cell_type":"code","metadata":{"id":"oCVNLlfVS9-1"},"source":["###_----main ---###\r\n","features_bianca = extract_features(bianca_walking)\r\n","features_giacomo = extract_features(giacomo_walking)\r\n","\r\n","compare_features(features_bianca[0], features_bianca[1]) # similarità alta\r\n","compare_features(features_bianca[0], features_giacomo[1]) # similarità bassa"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"1W00KYwNjkLv","outputId":"fb193884-0029-459f-d32b-120e540f8bea"},"source":["1) Output"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(7352, 128, 9) (7352, 1)\n","(2947, 128, 9) (2947, 1)\n","(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n",">#1: 90.058\n",">#2: 91.144\n",">#3: 91.347\n",">#4: 90.227\n",">#5: 91.483\n",">#6: 90.058\n",">#7: 90.329\n",">#8: 89.345\n",">#9: 91.924\n",">#10: 90.804\n","[90.05768299102783, 91.14353656768799, 91.34713411331177, 90.22734761238098, 91.48286581039429, 90.05768299102783, 90.32914638519287, 89.34509754180908, 91.923987865448, 90.80420732498169]\n","Accuracy: 90.672% (+/-0.758)\n"],"name":"stdout"}]}]}