import numpy as np
from sklearn import metrics
from sklearn.preprocessing import LabelBinarizer
from keras.callbacks import EarlyStopping, Callback, ModelCheckpoint
from Networks.Models import lstm_keras, rcnn_keras, lstm_keras1, autoencoder_model

import matplotlib
matplotlib.use('Agg')

import seaborn as sns


saved_weights_path = "Weights/"
confusion_matrix_path = "confusion_matrix/"
def train_network(X_train, X_test, y_train, y_test, model_type, TEST, LABELS, activity, subject):

    batch_size = 150
    epochs = 300

    # Some debugging info
    print("Some useful info to get an insight on dataset's shape and normalisation:")
    print("(X shape, y shape, every X's mean, every X's standard deviation)")
    print(X_test.shape, y_test.shape, np.mean(X_test), np.std(X_test))
    print("The dataset is therefore properly normalised, as expected, but not yet one-hot encoded.")
    input_shape = (X_train.shape[1], X_train.shape[2])
    if model_type == "LSTM":
        n_classes = 30
        model = lstm_keras(input_shape, n_classes)
        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])
    if model_type == "LSTM_binary":
        n_classes = 1
        model = lstm_keras1(input_shape, n_classes)
        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    if model_type == "LSTM_ae":
        model = autoencoder_model(X_train)
        model.compile(optimizer='adam', loss='mae')
        model.summary()

    #model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])
    #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_crossentropy'])

    # perform one-hot encoding on the labels
    if model_type != "LSTM_ae":
        lb = LabelBinarizer()
        y_test = lb.fit_transform(y_test)
        y_train = lb.fit_transform(y_train)
    if model_type == "LSTM_binary" or model_type == "LSTM_ae":
        checkpoint = ModelCheckpoint(saved_weights_path + model_type + activity +  "_" + str(subject) + ".hdf5", monitor='loss', verbose=1,
                                     save_best_only=True, mode='auto', period=1)
    else:
        checkpoint = ModelCheckpoint(saved_weights_path + model_type  + activity + ".hdf5", monitor='loss', verbose=1,
                                 save_best_only=True, mode='auto', period=1)

    if TEST == False:
        if model_type == "LSTM_ae":
            history = model.fit(
                X_train,
                X_train,
                validation_data=(X_test, X_test),
                epochs=epochs,
                batch_size=batch_size,
                callbacks=[checkpoint]
            )
        else:
            history = model.fit(
                X_train,
                y_train,
                validation_data=(X_test, y_test),
                epochs=epochs,
                batch_size=batch_size,
                callbacks=[checkpoint]
            )

    if model_type == "LSTM" :
        model.load_weights(saved_weights_path + model_type + activity + ".hdf5")
        y_pred_ohe = model.predict(X_test)
        y_pred_labels = np.argmax(y_pred_ohe, axis=1)
        y_true_labels = np.argmax(y_test, axis=1)
        confusion_matrix = metrics.confusion_matrix(y_true=y_true_labels, y_pred=y_pred_labels)

        matplotlib.pyplot.figure(figsize=(16, 14))
        sns.set(style='whitegrid', palette='muted', font_scale=1.5)
        sns.heatmap(confusion_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt="d");
        matplotlib.pyplot.title("Confusion matrix")
        matplotlib.pyplot.ylabel('True label')
        matplotlib.pyplot.xlabel('Predicted label')
        matplotlib.pyplot.savefig(confusion_matrix_path + model_type + "_" + activity)

    if model_type == "LSTM_binary" :
        model.load_weights(saved_weights_path + model_type + activity +  "_" + str(subject) + ".hdf5")

        y_pred_ohe = model.predict(X_test)
        y_pred = []
        for y in y_pred_ohe:
            if y > 0.5:
                y_pred.append(1)
            else:
                y_pred.append(0)
        y_true = []
        for y in y_test:
            if y > 0.5:
                y_true.append(1)
            else:
                y_true.append(0)

        confusion_matrix = metrics.confusion_matrix(y_true=y_true, y_pred=y_pred)

        matplotlib.pyplot.figure(figsize=(16, 14))
        sns.set(style='whitegrid', palette='muted', font_scale=1.5)
        sns.heatmap(confusion_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt="d");
        matplotlib.pyplot.title("Confusion matrix")
        matplotlib.pyplot.ylabel('True label')
        matplotlib.pyplot.xlabel('Predicted label')
        matplotlib.pyplot.savefig(confusion_matrix_path + model_type + "_" + activity + "_" + str(subject))


    if model_type == "LSTM_ae":
        model.load_weights(saved_weights_path + model_type + activity +  "_" + str(subject) + ".hdf5")

        # plot the loss distribution of the training set
        X_pred = model.predict(X_train)
        print(len(X_pred))
        X_pred = X_pred.reshape(X_pred.shape[0], X_pred.shape[1] * X_pred.shape[2])
        Xtrain = X_train.reshape(X_pred.shape[0], X_train.shape[1] * X_train.shape[2])
        scored = np.mean(np.abs(X_pred - Xtrain), axis=1)
        matplotlib.pyplot.figure(figsize=(16, 9), dpi=80)
        matplotlib.pyplot.title('Loss Distribution', fontsize=16)
        sns.distplot(scored, bins=20, kde=True, color='blue');
        matplotlib.pyplot.xlim([0.0, .5])

        X_pred = model.predict(X_test)
        X_pred = X_pred.reshape(X_pred.shape[0], X_pred.shape[1] * X_pred.shape[2])
        X_test = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])

        mse = np.mean(np.abs(X_test - X_pred), axis=1)
        thresholds = [0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29]

        for threshold in thresholds:
            print(threshold)
            anomalies = mse > threshold
            id = 0
            corrects_positive = 0
            total_positive = 0
            total_negative = 0
            corrects_negative = 0
            wrong_positive = 0
            wrong_negative = 0

            for y in y_test:
                if int(y[0]) == 1:
                    total_positive +=1
                    if anomalies[id] == True:
                        corrects_positive +=1
                    else:
                        wrong_positive +=1
                else:
                    total_negative +=1
                    if anomalies[id] == False:
                        corrects_negative +=1
                    else:
                        wrong_negative +=1
                id +=1
            print(str(corrects_positive) + "/" + str(total_positive))
            print(str(corrects_negative) + "/" + str(total_negative))

            print("Accuracy " +  str((corrects_positive + corrects_negative)/(total_positive + total_negative)))

